项目相关：
主要调研序列并行相关的并行策略，首先就是现有的一些开源框架例如megatron, deepspeed等看了一些他们相关的一些并行策略，接着通过结合现有的相关并行和加速算法设计了一个序列并行 + 张量并行的混合并行方案。
CPP讲一下，适用场景有哪些：
CPP主要是借鉴了传统的G-Pipe的流水线并行，G-pipe的话主要是micro-batch based的PP并行。首先PP会有几个问题，第一个PP动态峰值激活比较大，序列越长越会受到显存约束，第二个是PP会存在micro-batch不等长的问题，可能会导致每个请求推理时间不同进而在PP进程中加入额外bubble。第三个是PP对于长序列小batch的场景不是很友好。所以CPP在原始PP的基础上首先引入了sequence维度的切分，也就是进一步细化了流水线并行的颗粒度。在大语言模型中面对causal mask比较多，所以其实每个时刻的输出只和它前面计算结果相关，所以CPP天然的就能够和这种自回归推理相契合。但是同时这个CPP也有几个需要注意的问题，第一个就是token-level的切分会进一步降低计算利用率，也就是每轮推理的Token数量过少的时候会让计算效率显著降低。另一个是如果切分的不够均匀的话会在pp流程中出现空泡，所以这个切分策略是一个非常核心的点。
然后具体涉及到切分策略了，这个切分策略实际上是以时延为导向的，也就是希望每轮推理的时长是比较均匀的。我们这里首先对固定token数量的推理时延进行建模，建模的话主要分成三部分分别是计算，访存和通讯。计算这边主要考虑的还是矩阵乘，同时需要基于causal mask针对不同的chunk的SA的耗时是不一样的。基于chunk的时延来决定具体怎么切，切分方式呢先对每个请求的sequence来确定切分策略，找到最优切分方式。然后再以整个batch为颗粒度通过动态规划找到最优切分策略，最后达到的效果就是我的第x轮会跑第x1到xn个请求中的x1-xn个token。通过这样的方式实现了这样细颗粒度的PP并行。CPP的适用场景首先在长序列场景下的可操作空间更大了，实测的效果在短序列上表现的效果和传统PP差距不是很大，序列越长优势会越明显一点，因为能减少bubble时间以及整体的内部空泡。另外非常适合通信带宽较差的一些场景，原本PP的通讯量就很小再加上进一步切分了chunk，打散了整个通信量。

量化为什么能加速
是存储问题，float型比int8型多占4倍存储。二是计算消耗资源问题，2个float相乘需要消耗4个DSP48E资源，而两个int8只需要一个DSP48E乘法器资源。
融合量化算子的优点是什么，换句话说融合和不融合会有什么区别
融合算子首先减少了算子间的数据搬运，例如前一个算子的计算结果需要从L1搬回GM，然后再从GM搬运到下一个算子，会增加额外搬运。另一个是中间变量的传输，例如量化算子会计算出scale和offset，这些中间变量会单独拿出来传递给后面的算子，所以会增加额外的变量开销
量化的整个计算流程是什么样的，W8A8和W816
首先量化分为weight量化和activation量化，weight量化主要是针对权重，权重的话在模型训练完成后如果不继续进行微调的话可以通过校准集对权重进行量化。activation的量化主要还是在在线推理的过程中通过插入额外算子去获得量化activation所需的scale和offset，然后对activation进行一个在线推理量化。
先说W8A16的量化流程，首先前一个算子的激活值fp16输入进入算子后，int8的权重会反量化成fp16，然后算子内部保持fp16精度的计算当计算结束后再根据输出的数据类型决定是否要进一步量化和反量化
W8A8的量化流程是，假定前一个算子的输出是fp16的结果，fp16进入算子后会量化成int8后和int8的权重计算，计算后得到的结果会反量化到对应的输出dtype然后输出到算子外部

校准集是如何在量化中生效的
校准集主要应用在激活量化中，由于激活值在推理过程中是动态的，所以需要通过校准集来确定激活值的范围例如min, max参数，进而后续对激活进行int8或者更低精度的量化和反量化。所以校准集的作用主要是确定激活值的范围进而后续确定量化的参数
为什么不直接训练低精度的模型？
之所以不直接训练int8模型，是因为训练需要反向传播和梯度下降，int8不好做。如果直接训练int8我认为模型的学习和表达能力会大幅度下降，最终达不到浮点或者混精度的效果

模型剪枝一定要了解一下
讲一下什么是MFU？有哪些影响因素会印象MFU？有哪些提高MFU的手段？
Model Flops utilization模型算力利用率，具体是模型单轮前向反向的flops / 单卡算力*卡数*单轮耗时。分子是整个模型的理论flops，分母是理论上推理前反向的这段时间GPU理论上的最大FLOPS。所以通过这个比值大概可以看出来算力究竟发挥了多少，影响MFU的因素有很多首先就是数据的IO，batch size/sequence长度等也会影响算子的计算效率，集群间的通讯效率等等这些影响前向的因素都会印象MFU。提高MFU的手段我个人理解主要还是从提高整个模型的前向推理效率作为出发点，我们可以设计更优的通讯方式提高通讯效率，可以一定程度上打高batch size提高matmul的计算效率，也可以通过一些算子融合减少数据搬运的IO时间等等。

整个大模型的推理流程是怎样的

量化详解
https://zhuanlan.zhihu.com/p/58182172
混精度训练
保留一份FP32的主权重（Master-Weights），同时在训练中使用FP16存储权重、激活、梯度等数据。在参数更新的过程汇总，用FP16更新FP32的主权重。
https://hub.baai.ac.cn/view/16045





